{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0491070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a2caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return a list of all files present in a directory (using os library)\n",
    "def GenerateFilesList(Path):\n",
    "    return os.listdir(Path + '/')\n",
    "\n",
    "# function to extract all text in documents from a directory\n",
    "def ExtractText(Path, FilesList):\n",
    "    text=\"\"\n",
    "    for x in FilesList:\n",
    "        with open(f\"{Path}/{x}\") as file:\n",
    "            #opening every document and capturing its content\n",
    "            file_text = file.read()\n",
    "            text = text + file_text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a039c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split the text into words and convert them all to lowercase (using re library)\n",
    "# text --> lower case words\n",
    "def SplitAndLowerText(text):\n",
    "    #[^A-Za-z\\'']+   --> regex for non-aplhabetic chars (and apostrophe) occuring 1 or more times [used as seperator for split]\n",
    "    words = re.split('[^A-Za-z\\']+',text)\n",
    "    #converting all words to lower case to standardize\n",
    "    lower_case_words=[word.lower() for word in words]\n",
    "    return lower_case_words\n",
    "\n",
    "\n",
    "# function to remove stopwords from list of words and return a list of cleaned words\n",
    "# lower case words --> cleaned words\n",
    "def StopwordsRemoval(words):\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords_nltk=set(stopwords.words('english'))\n",
    "    cleaned_words=[word for word in words if word not in stopwords_nltk]\n",
    "    return cleaned_words\n",
    "\n",
    "\n",
    "# function to remove duplicates and return list of unique words\n",
    "# cleaned words --> unique words\n",
    "def RemoveDuplicates(words):\n",
    "    unique_words=[]\n",
    "    for word in words:\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "    return unique_words\n",
    "\n",
    "\n",
    "# function to perform stemming on words list\n",
    "# unique words --> stemmed words\n",
    "def Stemmer(words):\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stemmed_words=[]\n",
    "    for word in words:\n",
    "        stemmed_words.append(PorterStemmer().stem(word))\n",
    "    return stemmed_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d0fe2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create dictionary of inverse index from words list\n",
    "def GenerateDictionary(words, Path, FilesList):\n",
    "    dict={}\n",
    "    for word in words:\n",
    "        dict[word]=[]\n",
    "        \n",
    "    for word in words:\n",
    "        for x in range(len(FilesList)):\n",
    "            with open(f\"{Path}/{FilesList[x]}\") as file:\n",
    "                file_text = file.read()\n",
    "                if word in file_text.lower():\n",
    "                    dict[word].append(x)\n",
    "    return dict\n",
    "\n",
    "def GenerateDictionaryV2(UniqueWords, StemmedWords, Path, FilesList):\n",
    "    dict={}\n",
    "    for word in StemmedWords:\n",
    "        dict[word]=[]\n",
    "        \n",
    "    for word in UniqueWords:\n",
    "        for x in range(len(FilesList)):\n",
    "            with open(f\"{Path}/{FilesList[x]}\") as file:\n",
    "                file_text = file.read()\n",
    "                if word in file_text.lower():\n",
    "                    if x not in dict[PorterStemmer().stem(word)]:\n",
    "                        dict[PorterStemmer().stem(word)].append(x)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0080574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return TRUE/FALSE for whether string matches with wildcard pattern or not\n",
    " \n",
    "def StringMatch(strr, pattern, slen, plen):\n",
    " \n",
    "    # empty pattern (plen=0) can only match with empty string\n",
    "    if (plen == 0):\n",
    "        return (slen == 0)\n",
    " \n",
    "    # creating 2D array of 0-M X 0-N to store subsolutions \n",
    "    lookup = [[False for i in range(plen + 1)] for j in range(slen + 1)]\n",
    " \n",
    "    # empty pattern matches with empty string\n",
    "    lookup[0][0] = True\n",
    " \n",
    "    # only '*' can match with empty string\n",
    "    for j in range(1, plen + 1):\n",
    "        if (pattern[j - 1] == '*'):\n",
    "            lookup[0][j] = lookup[0][j - 1]\n",
    " \n",
    "    # filling the table by following the rules below\n",
    "    for i in range(1, slen + 1):\n",
    "        for j in range(1, plen + 1):\n",
    " \n",
    "            # if last char of pattern is '*': \n",
    "            # (a) either * is zero chars  \n",
    "            #       --> solution for [i][j-1] is applicable\n",
    "            # (b) * is a char \\\n",
    "            #       --> solution for [i-1][j] is applicable (since extra char from string is encorporated in *)\n",
    "            if (pattern[j - 1] == '*'):\n",
    "                lookup[i][j] = lookup[i][j - 1] or lookup[i - 1][j]\n",
    " \n",
    "            # if last two chars of both are same or last char of pattern is '?', solution for [i-1][j-1] is applicable\n",
    "            elif ( (pattern[j - 1] == '?') or (strr[i - 1] == pattern[j - 1]) ):\n",
    "                lookup[i][j] = lookup[i - 1][j - 1]\n",
    "                \n",
    "            else:\n",
    "                lookup[i][j] = False\n",
    " \n",
    "    return lookup[slen][plen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a1a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return Edit Distance between two strings \n",
    "# [taking first string to be mutable, second string to be immutable]\n",
    "\n",
    "def EditDistance(str1, str2, len1, len2):\n",
    "    # creating 2D array of 0-len1 X 0-len2 to store subsolutions    \n",
    "    dp = [[0 for x in range(len2 + 1)] for x in range(len1 + 1)]\n",
    " \n",
    "    # filling 2D array \n",
    "    for i in range(len1 + 1):\n",
    "        for j in range(len2 + 1):\n",
    " \n",
    "            # if first string is empty, only way is to insert all characters of second string\n",
    "            if i == 0:\n",
    "                dp[i][j] = j    # Min. operations = j (length of second string)\n",
    " \n",
    "            # if second string is empty, only way is to remove all characters of first string\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i    # Min. operations = i (length of first string)\n",
    " \n",
    "            # if last characters are same, then distance = d[i-1][j-1]\n",
    "            elif str1[i-1] == str2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    " \n",
    "            # if last characters are different, consider insert(one char short)/remove(one extra char)/replace(diff char)\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i][j-1],        # Insert\n",
    "                                   dp[i-1][j],        # Remove\n",
    "                                   dp[i-1][j-1])    # Replace\n",
    " \n",
    "    return dp[len1][len2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4122ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to spellcheck a word, returns word/closest word\n",
    "\n",
    "def SpellCheck(word, VocabList):\n",
    "    min = 10000\n",
    "    closest = \"\"\n",
    "    for x in VocabList:\n",
    "        if (StringMatch(x, word, len(x), len(word))):\n",
    "            return word\n",
    "        else:\n",
    "            distance = EditDistance(word, x, len(word), len(x))\n",
    "            if (distance < min):\n",
    "                min = distance\n",
    "                closest = x\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75841527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining bitwise functions (using lists)\n",
    "\n",
    "# bitwise AND\n",
    "def BitwiseAND(list1, list2):\n",
    "    bitwise_op = [w1 & w2 for (w1, w2) in zip(list1, list2)]\n",
    "    return bitwise_op\n",
    "\n",
    "# bitwise OR\n",
    "def BitwiseOR(list1, list2):\n",
    "    bitwise_op = [w1 | w2 for (w1, w2) in zip(list1, list2)]\n",
    "    return bitwise_op\n",
    "\n",
    "# bitwise NOT\n",
    "def BitwiseNOT(list1, list2):\n",
    "    bitwise_op = [not w1 for w1 in list2]\n",
    "    bitwise_op = [int(b == True) for b in bitwise_op]\n",
    "    bitwise_op = [w1 & w2 for (w1,w2) in zip(list1,bitwise_op)]\n",
    "    return bitwise_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28305b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTION\n",
    "def Execute(query_input):\n",
    "    query = query_input.split()\n",
    "\n",
    "    #boolean connectors\n",
    "    connecting_words = []\n",
    "    #content words\n",
    "    different_words = []\n",
    "\n",
    "    for word in query:\n",
    "        if word.lower() != \"and\" and word.lower() != \"or\" and word.lower() != \"not\":\n",
    "            different_words.append(word.lower())\n",
    "        else:\n",
    "            connecting_words.append(word.lower())\n",
    "\n",
    "    zeroes_and_ones = []\n",
    "    zeroes_and_ones_of_all_words = []\n",
    "\n",
    "    for word in (different_words):\n",
    "        #if word is normal query\n",
    "        if word.isalpha():\n",
    "            closest = SpellCheck(word, unique_words)\n",
    "            stemmed = PorterStemmer().stem(closest)\n",
    "            zeroes_and_ones = [0] * len(Files_List)\n",
    "            for x in dictV2[stemmed]:\n",
    "              zeroes_and_ones[x] = 1\n",
    "            zeroes_and_ones_of_all_words.append(zeroes_and_ones)\n",
    "        \n",
    "        #if word in wildcary query\n",
    "        else:\n",
    "            matches = []\n",
    "            for x in unique_words:\n",
    "                if StringMatch(x, word, len(x), len(word)):\n",
    "                    matches.append(x)\n",
    "\n",
    "            stemmed_matches=[]\n",
    "            for x in matches:\n",
    "                stemmed = PorterStemmer().stem(x)\n",
    "                if stemmed not in stemmed_matches:\n",
    "                    stemmed_matches.append(stemmed)\n",
    "\n",
    "            zeroes_and_ones = [0] * len(Files_List)\n",
    "            temp_zeroes_and_ones = [0] * len(Files_List)\n",
    "            for match in stemmed_matches:\n",
    "                for x in dictV2[match]:\n",
    "                    temp_zeroes_and_ones[x] = 1\n",
    "                zeroes_and_ones = BitwiseOR(zeroes_and_ones, temp_zeroes_and_ones)\n",
    "            zeroes_and_ones_of_all_words.append(zeroes_and_ones)\n",
    "\n",
    "\n",
    "    for word in connecting_words:\n",
    "        # we take the first two words from query (for which the corresponding connecting_word is taken)\n",
    "        word_list1 = zeroes_and_ones_of_all_words[0]\n",
    "        word_list2 = zeroes_and_ones_of_all_words[1]\n",
    "\n",
    "        if word == \"and\":\n",
    "            # performs bitwise operation AND on the two lists\n",
    "            bitwise_op = BitwiseAND(word_list1,word_list2)\n",
    "            zeroes_and_ones_of_all_words.remove(word_list1)\n",
    "            zeroes_and_ones_of_all_words.remove(word_list2)\n",
    "            zeroes_and_ones_of_all_words.insert(0, bitwise_op)\n",
    "        elif word == \"or\":\n",
    "            # performs bitwise operation OR on the two lists\n",
    "            bitwise_op = BitwiseOR(word_list1,word_list2)\n",
    "            zeroes_and_ones_of_all_words.remove(word_list1)\n",
    "            zeroes_and_ones_of_all_words.remove(word_list2)\n",
    "            zeroes_and_ones_of_all_words.insert(0, bitwise_op)\n",
    "        elif word == \"not\":\n",
    "            # performs bitwise operation NOT on the two lists\n",
    "            bitwise_op = BitwiseNOT(word_list1,word_list2)\n",
    "            zeroes_and_ones_of_all_words.remove(word_list2)\n",
    "            zeroes_and_ones_of_all_words.remove(word_list1)\n",
    "            zeroes_and_ones_of_all_words.insert(0, bitwise_op)\n",
    "    # this results in a final list with bitwise operations done over the entire query\n",
    "\n",
    "    files_found = []    \n",
    "    if zeroes_and_ones_of_all_words:\n",
    "        index_list = zeroes_and_ones_of_all_words[0]\n",
    "    else:\n",
    "        index_list = []\n",
    "\n",
    "    for index in range(len(index_list)):\n",
    "        if index_list[index]==1:\n",
    "            files_found.append(Files_List[index])\n",
    "\n",
    "    print(\"\\n Files Found:\",len(files_found))\n",
    "    print(\"List of files found:\\n\", files_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c253f96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# opening files and reading text\n",
    "path = \"dataset\"\n",
    "Files_List = GenerateFilesList(path)\n",
    "text = ExtractText(path, Files_List)\n",
    "\n",
    "# preprocessing\n",
    "lower_case_words = SplitAndLowerText(text)\n",
    "cleaned_words = StopwordsRemoval(lower_case_words)\n",
    "unique_words = RemoveDuplicates(cleaned_words)\n",
    "stemmed_words = Stemmer(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7040f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formulating inverse index\n",
    "dict = GenerateDictionary(unique_words, path, Files_List)\n",
    "dictV2 = GenerateDictionaryV2(unique_words, stemmed_words, path, Files_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5482665c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Files Found: 1\n",
      "List of files found:\n",
      " ['titus-andronicus_TXT_FolgerShakespeare.txt']\n"
     ]
    }
   ],
   "source": [
    "Execute(\"androni?us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc7febf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Files Found: 2\n",
      "List of files found:\n",
      " ['the-two-gentlemen-of-verona_TXT_FolgerShakespeare.txt', 'titus-andronicus_TXT_FolgerShakespeare.txt']\n"
     ]
    }
   ],
   "source": [
    "Execute(\"andronics or lucetta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a940b58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Files Found: 0\n",
      "List of files found:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "Execute(\"andronics not titus\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
